{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets #sklearn é uma das lib mais utilizadas em ML, ela contém, além dos \n",
    "                            #datasets, várias outras funções úteis para a análise de dados\n",
    "                            # essa lib será sua amiga durante toda sua carreira\n",
    "import pandas as pd  # importa a lib Pandas. Essa lib é utilizada para lidar com dataframes (TABELAS) \n",
    "                     #de forma mais amigável. \n",
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score, cross_val_predict # esse método é utilizado para dividir o \n",
    "                                                    # conjunto de dados em grupos de treinamento e test\n",
    "from sklearn.svm import SVC      #importa o algoritmo svm para ser utilizado \n",
    "from sklearn import tree         # importa o algoritmo arvore de decisão\n",
    "from sklearn.linear_model import LogisticRegression #importa o algoritmo de regressão logística\n",
    "from sklearn.metrics import mean_absolute_error #utilizada para o calculo do MAE\n",
    "from sklearn.metrics import mean_squared_error #utilizada para o calculo do MSE\n",
    "from sklearn.metrics import r2_score #utilizada para o calculo do R2\n",
    "from sklearn import metrics  #utilizada para as métricas de comparação entre os métodos\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "got_dataset = pd.read_csv('../input/game-of-thrones/character-predictions.csv')  #realiza a leitura do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "got_dataset.info() #conhecendo o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None) #comando utilizado para mostrar a tabela\n",
    "got_dataset.head()  #mostrando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nans = got_dataset.isna().sum() #contando a quantidade de valores nulos\n",
    "nans[nans > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conhecendo o dataset - Veja que Idade tem problema\n",
    "got_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tamanho do dataset\n",
    "len(got_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analisando os dados nulos\n",
    "print(got_dataset[\"age\"].mean())   #possível erro no nosso dataset (média negativa para a idade?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realizando uma maior análise do dataset\n",
    "print(got_dataset[\"name\"][got_dataset[\"age\"] < 0])\n",
    "print(got_dataset['age'][got_dataset['age'] < 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#substituindo os valores negativos\n",
    "got_dataset.loc[1684, \"age\"] = 25.0\n",
    "got_dataset.loc[1868, \"age\"] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(got_dataset[\"age\"].mean())   #verificando, novamente, a idade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trabalhando com dados nulos\n",
    "got_dataset[\"age\"].fillna(got_dataset[\"age\"].mean(), inplace=True) #substituindo os valores nulos pela média da coluna\n",
    "got_dataset[\"culture\"].fillna(\"\", inplace=True) #preenchendo os valores nulos da coluna cultura com uma string nula\n",
    "\n",
    "# preenchendo os demais valores com -1\n",
    "got_dataset.fillna(value=-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#realizando o boxplot \n",
    "got_dataset.boxplot(['alive','popularity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analisando a \"mortalidade\" dos personagens\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "f,ax=plt.subplots(2,2,figsize=(17,15))\n",
    "sns.violinplot(\"isPopular\", \"isNoble\", hue=\"isAlive\", data=got_dataset ,split=True, ax=ax[0, 0])\n",
    "ax[0, 0].set_title('Noble and Popular vs Mortality')\n",
    "ax[0, 0].set_yticks(range(2))\n",
    "\n",
    "sns.violinplot(\"isPopular\", \"male\", hue=\"isAlive\", data=got_dataset ,split=True, ax=ax[0, 1])\n",
    "ax[0, 1].set_title('Male and Popular vs Mortality')\n",
    "ax[0, 1].set_yticks(range(2))\n",
    "\n",
    "sns.violinplot(\"isPopular\", \"isMarried\", hue=\"isAlive\", data=got_dataset ,split=True, ax=ax[1, 0])\n",
    "ax[1, 0].set_title('Married and Popular vs Mortality')\n",
    "ax[1, 0].set_yticks(range(2))\n",
    "\n",
    "\n",
    "sns.violinplot(\"isPopular\", \"book1\", hue=\"isAlive\", data=got_dataset ,split=True, ax=ax[1, 1])\n",
    "ax[1, 1].set_title('Book_1 and Popular vs Mortality')\n",
    "ax[1, 1].set_yticks(range(2))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retirando algumas colunas \n",
    "drop = [\"S.No\", \"pred\", \"alive\", \"plod\", \"name\", \"isAlive\", \"DateoFdeath\"]\n",
    "got_dataset.drop(drop, inplace=True, axis=1)\n",
    "\n",
    "#Salvando uma cópia do dataset para aplicar o hotencoder\n",
    "got_dataset_2 = got_dataset.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformando os dados categóricos em one-hot-encoder\n",
    "got_dataset = pd.get_dummies(got_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "got_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "got_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando o dataset entre entradas e saídas\n",
    "x = got_dataset.iloc[:,1:].values\n",
    "y = got_dataset.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicando o modelo de validação cruzada\n",
    "# divide o dataset entre 5 diferentes grupos\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kfold.get_n_splits())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construindo os modelos de classificação\n",
    "modelos = [LogisticRegression(solver='liblinear'), RandomForestClassifier(n_estimators=400, random_state=42), \n",
    "          DecisionTreeClassifier(random_state=42), svm.SVC(kernel='rbf', gamma='scale', random_state=42), \n",
    "          KNeighborsClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utilizando a validação cruzada\n",
    "mean=[]\n",
    "std=[]\n",
    "for model in modelos:\n",
    "    result = cross_val_score(model, x, y, cv=kfold, scoring=\"accuracy\", n_jobs=-1)\n",
    "    mean.append(result)\n",
    "    std.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificadores=['Regressão Logística', 'Random Forest', 'Árvore de Decisão', 'SVM', 'KNN']\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "for i in range(len(mean)):\n",
    "    sns.distplot(mean[i], hist=False, kde_kws={\"shade\": True})\n",
    "    \n",
    "plt.title(\"Distribuição de cada um dos classificadores\", fontsize=15)\n",
    "plt.legend(classificadores)\n",
    "plt.xlabel(\"Acurácia\", labelpad=20)\n",
    "plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Realizando a previsão dos classificadores**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Quais algoritmos escollher?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo o dataset entre treinamento 80% e teste 20%\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, \n",
    "                                                    shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#escolhendo o svm e a floresta randomica\n",
    "svm_clf = svm.SVC(C=0.9, gamma=0.1, kernel='rbf', probability=True, random_state=42)\n",
    "rf_clf = RandomForestClassifier(n_estimators=400, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Treina os modelos\n",
    "svm_clf.fit(x_train, y_train)\n",
    "rf_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtém as probabilidades previstas\n",
    "svm_prob = svm_clf.predict_proba(x_test)\n",
    "rf_prob = rf_clf.predict_proba(x_test)\n",
    "\n",
    "# Valores reais\n",
    "svm_preds = np.argmax(svm_prob, axis=1)\n",
    "rf_preds = np.argmax(rf_prob, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analisando os modelos \n",
    "cm = metrics.confusion_matrix(y_test, svm_preds)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "cm2 = metrics.confusion_matrix(y_test, rf_preds)\n",
    "cm2 = cm2.astype('float') / cm2.sum(axis=1)[: , np.newaxis]\n",
    "\n",
    "classes = [\"Morto\", \"Vivo\"]\n",
    "f, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax[0].set_title(\"SVM\", fontsize=15.)\n",
    "sns.heatmap(pd.DataFrame(cm, index=classes, columns=classes), \n",
    "            cmap='winter', annot=True, fmt='.2f', ax=ax[0]).set(xlabel=\"Previsao\", ylabel=\"Valor Real\")\n",
    "\n",
    "ax[1].set_title(\"Random Forest\", fontsize=15.)\n",
    "sns.heatmap(pd.DataFrame(cm2, index=classes, columns=classes), \n",
    "            cmap='winter', annot=True, fmt='.2f', ax=ax[1]).set(xlabel=\"Previsao\", \n",
    "                                                                ylabel=\"Valor Real\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
